{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/dhanyaharish/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = movie_reviews.categories()\n",
    "reviews = []\n",
    "for cat in cats:\n",
    "    for fid in movie_reviews.fileids(cat):\n",
    "        review = (list(movie_reviews.words(fid)),cat)\n",
    "        reviews.append(review)\n",
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wd_in_reviews = nltk.FreqDist(wd.lower() for wd in movie_reviews.words())\n",
    "top_wd_in_reviews = [list(wds) for wds in zip(*all_wd_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_ft(review,top_words):\n",
    "    review_wds = set(review)\n",
    "    ft = {}\n",
    "    for wd in top_words:\n",
    "        ft['word_present({})'.format(wd)] = (wd in review_wds)\n",
    "    return ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_wd_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "word_present(outstanding) = True              pos : neg    =     12.5 : 1.0\n",
      "     word_present(mulan) = True              pos : neg    =      8.9 : 1.0\n",
      "    word_present(seagal) = True              neg : pos    =      7.4 : 1.0\n",
      "word_present(wonderfully) = True              pos : neg    =      7.0 : 1.0\n",
      "     word_present(damon) = True              pos : neg    =      6.1 : 1.0\n",
      "    word_present(poorly) = True              neg : pos    =      6.0 : 1.0\n",
      "      word_present(lame) = True              neg : pos    =      5.9 : 1.0\n",
      "word_present(ridiculous) = True              neg : pos    =      5.8 : 1.0\n",
      "    word_present(wasted) = True              neg : pos    =      5.4 : 1.0\n",
      "     word_present(awful) = True              neg : pos    =      5.4 : 1.0\n",
      "       word_present(era) = True              pos : neg    =      5.3 : 1.0\n",
      "     word_present(waste) = True              neg : pos    =      5.2 : 1.0\n",
      "     word_present(snake) = True              neg : pos    =      5.0 : 1.0\n",
      "     word_present(worst) = True              neg : pos    =      4.7 : 1.0\n",
      "    word_present(allows) = True              pos : neg    =      4.4 : 1.0\n",
      "   word_present(unfunny) = True              neg : pos    =      4.3 : 1.0\n",
      "    word_present(stupid) = True              neg : pos    =      4.2 : 1.0\n",
      " word_present(pointless) = True              neg : pos    =      4.2 : 1.0\n",
      " word_present(portrayal) = True              pos : neg    =      4.1 : 1.0\n",
      "     word_present(hanks) = True              pos : neg    =      4.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vectorizer=None\n",
    "def get_train_test(train_set,test_set):\n",
    "    global dict_vectorizer\n",
    "    dict_vectorizer = DictVectorizer(sparse=False)\n",
    "    X_train, y_train = zip(*train_set)\n",
    "    X_train = dict_vectorizer.fit_transform(X_train)\n",
    "    X_test,y_test = zip(*test_set)\n",
    "    X_test = dict_vectorizer.transform(X_test)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4, random_state=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)\n",
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words('english')\n",
    "all_words_in_reviews = nltk.FreqDist(word.lower() for word in movie_reviews.words() if word not in stopwords_list)\n",
    "top_words_in_reviews = [list(words) for words in zip(*all_words_in_reviews.most_common(2000))][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(ext_ft(d,top_words_in_reviews), c) for (d,c) in reviews]\n",
    "train_set, test_set = featuresets[200:], featuresets[:200]\n",
    "X_train,X_test,y_train,y_test = get_train_test(train_set,test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=4, random_state=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=4,random_state=10)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(X_test)\n",
    "print(accuracy_score(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('word_present(bad)', 0.015529669630700889), ('word_present(stupid)', 0.0071365303260568615), ('word_present(boring)', 0.006867331151253918), ('word_present(worst)', 0.0065533881391988645), ('word_present(ridiculous)', 0.005154484285257659), ('word_present(mess)', 0.004947554136504527), ('word_present(awful)', 0.00490327846463197), ('word_present(script)', 0.004867138224172507), ('word_present(life)', 0.004552713486366785), ('word_present(lame)', 0.004502582842268086), ('word_present(supposed)', 0.004149222376007494), ('word_present(dull)', 0.004088775330999942), ('word_present(waste)', 0.003918416767064426), ('word_present(perfect)', 0.003911777398889316), ('word_present(outstanding)', 0.0036064039823212692), ('word_present(excellent)', 0.0035788148536847362), ('word_present(plot)', 0.0034848590622247547), ('word_present(great)', 0.0033338059595372305), ('word_present(allows)', 0.003069991691742157), ('word_present(memorable)', 0.0030285097003528217)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhanyaharish/Documents/GitHub/deep-learning/pytorch/DL/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features_list = zip(dict_vectorizer.get_feature_names(),rf.feature_importances_)\n",
    "features_list = sorted(features_list, key=lambda x: x[1], reverse=True)\n",
    "print(features_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97630161a1b63923bdd9a0aa586c344c3f95acdbb7ddd6c880d3dbef6642c2e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('DL': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
