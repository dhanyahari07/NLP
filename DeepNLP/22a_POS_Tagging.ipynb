{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22a. POS Tagging.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXv36RDj7L5QnDs+xettR/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70QH6IQdpP47",
        "outputId": "c582018e-fec3-4318-9b93-294b2b11bd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JElHzKC2lJJm",
        "outputId": "447a898c-964a-4388-d5a1-f480ab165956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "stop_words=set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"My name is dhanya\""
      ],
      "metadata": {
        "id": "r_RyBJk6pGRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SS-vqR6plHa",
        "outputId": "e2f3fac4-ec84-445d-e963-30c59f03f3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized=sent_tokenize(text)\n",
        "\n",
        "for i in tokenized:\n",
        "    word_list=nltk.word_tokenize(i)\n",
        "    word_list =[w for w in word_list if not w in stop_words]\n",
        "    tagged=nltk.pos_tag(word_list)\n",
        "    print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W5ssX5SpJYq",
        "outputId": "26d5c96f-8af0-49be-e184-9ab54a9f9e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('My', 'PRP$'), ('name', 'NN'), ('dhanya', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing loading the library\n",
        "import spacy\n",
        "# python -m spacy download en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#POS-TAGGING\n",
        "# Process whole documents\n",
        "text = (\"\"\"My name is Dhanya. I love to work on data science problems. Please check out my github profile!\"\"\")\n",
        "doc = nlp(text)\n",
        "# Token and Tag\n",
        "for token in doc:\n",
        "  print(token, token.pos_)\n",
        "# You want list of Verb tokens\n",
        "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhuYgswWpUjV",
        "outputId": "8f1d707a-f0a0-4858-90fb-987979a9e6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My DET\n",
            "name NOUN\n",
            "is AUX\n",
            "Dhanya PROPN\n",
            ". PUNCT\n",
            "I PRON\n",
            "love VERB\n",
            "to PART\n",
            "work VERB\n",
            "on ADP\n",
            "data NOUN\n",
            "science NOUN\n",
            "problems NOUN\n",
            ". PUNCT\n",
            "Please INTJ\n",
            "check VERB\n",
            "out ADP\n",
            "my DET\n",
            "github PROPN\n",
            "profile NOUN\n",
            "! PUNCT\n",
            "Verbs: ['love', 'work', 'check']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXlE435JqQn4",
        "outputId": "c02626ae-9909-4e45-c1ec-0ae7292be18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
            "is be AUX VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. U.K. PROPN NNP compound X.X. False False\n",
            "startup startup NOUN NN dobj xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CR9F2N3hsqDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}