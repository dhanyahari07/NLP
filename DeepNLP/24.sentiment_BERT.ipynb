{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGsQkIwz0vyTCj9GdOzY+A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XnDovJFLmKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "281c4e9b-7070-490a-d706-6cf30b11c85d"
      },
      "source": [
        "! pip install -U bert-serving-server bert-serving-client\n",
        "# https://github.com/mtala3t/Identify-the-Sentiments-AV-NLP-Contest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-serving-server\n",
            "  Downloading bert_serving_server-1.10.0-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 268 kB/s \n",
            "\u001b[?25hCollecting bert-serving-client\n",
            "  Downloading bert_serving_client-1.10.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (1.1.0)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server) (22.3.0)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=e9e7020a6f724ebd9eb4b25477e611707726111d6132d0f1f3b5d8ad27e30a74\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, bert-serving-server, bert-serving-client\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-client-1.10.0 bert-serving-server-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://datahack.analyticsvidhya.com/contest/linguipedia-codefest-natural-language-processing-1/#About"
      ],
      "metadata": {
        "id": "Yz4371-4ze1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/"
      ],
      "metadata": {
        "id": "gt-gvNaEziyM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGB5mJFwMhVO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import pickle\n",
        "import logging\n",
        "from bert_serving.client import BertClient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlK4VUTIMFCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d161d9-ed12-414d-84dd-3dac4c9294a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "725A0CsCMz0a"
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAnL4-TQM0F-"
      },
      "source": [
        "# read data\n",
        "train = pd.read_csv(\"/content/drive/My Drive/sentiment_ELMo/train_2kmZucJ.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/sentiment_ELMo/test_oJQbWVk.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Wm6JP7M8yP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b18a467-4c79-47a7-bb04-5a4af367f7ee"
      },
      "source": [
        "print (train.shape, test.shape)\n",
        "print (train['label'].value_counts())\n",
        "print (train.head())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7920, 3) (1953, 2)\n",
            "0    5894\n",
            "1    2026\n",
            "Name: label, dtype: int64\n",
            "   id  label  \\\n",
            "0   1      0   \n",
            "1   2      0   \n",
            "2   3      0   \n",
            "3   4      0   \n",
            "4   5      1   \n",
            "\n",
            "                                                                                                                                 tweet  \n",
            "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone  \n",
            "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/  \n",
            "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu  \n",
            "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/  \n",
            "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReaOXeQoM-9b"
      },
      "source": [
        "# data cleaning: remove URL's from train and test\n",
        "train['clean_tweet'] = train['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "test['clean_tweet'] = test['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9rEdhzcNBPh"
      },
      "source": [
        "# remove twitter handles (@user)\n",
        "train['clean_tweet'] = train['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uhnoo-lNDVx"
      },
      "source": [
        "# remove punctuation marks\n",
        "punctuation = '.,\\'!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
        "\n",
        "train['clean_tweet'] = train['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
        "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9ZKIxglNFUD"
      },
      "source": [
        "# convert text to lowercase\n",
        "train['clean_tweet'] = train['clean_tweet'].str.lower()\n",
        "test['clean_tweet'] = test['clean_tweet'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMdxPeAGNICt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aff08d9f-b180-4fe1-dfd1-16a21f259a77"
      },
      "source": [
        "# remove numbers\n",
        "train['clean_tweet'] = train['clean_tweet'].str.replace(\"[0-9]\", \" \")\n",
        "test['clean_tweet'] = test['clean_tweet'].str.replace(\"[0-9]\", \" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85iLhrMCNJ-e"
      },
      "source": [
        "# remove whitespaces\n",
        "train['clean_tweet'] = train['clean_tweet'].apply(lambda x:' '.join(x.split()))\n",
        "test['clean_tweet'] = test['clean_tweet'].apply(lambda x: ' '.join(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23GzqqUrNMTj"
      },
      "source": [
        "#Normalize the words to its base form\n",
        "# import spaCy's language model\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj6qvaIENOdF"
      },
      "source": [
        "# function to lemmatize text\n",
        "def lemmatization(texts):\n",
        "    output = []\n",
        "    for i in texts:\n",
        "        s = [token.lemma_ for token in nlp(i)]\n",
        "        output.append(' '.join(s))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6AUM30KNRTy"
      },
      "source": [
        "train['clean_tweet'] = lemmatization(train['clean_tweet'])\n",
        "test['clean_tweet'] = lemmatization(test['clean_tweet'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaxW1iFjNUUm"
      },
      "source": [
        "# Extract BERT embeddings function\n",
        "def bert_vectors(x):\n",
        "  \n",
        "    # make a connection with the BERT server using it's ip address\n",
        "    bc = BertClient()\n",
        "    \n",
        "    return bc.encode(x.tolist())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNozUrJZNWsJ"
      },
      "source": [
        "# Extract BERT embeddings\n",
        "bert_train = bert_vectors(train['clean_tweet'])\n",
        "bert_test = bert_vectors(test['clean_tweet'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlOcCyM4NYzJ"
      },
      "source": [
        "# save bert_train_new\n",
        "pickle_out = open(\"bert_train_03032019.pickle\",\"wb\")\n",
        "pickle.dump(bert_train, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5BOYXpTNanj"
      },
      "source": [
        "# save bert_test_new\n",
        "pickle_out = open(\"bert_test_03032019.pickle\",\"wb\")\n",
        "pickle.dump(bert_test, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObmcVLaSNchI"
      },
      "source": [
        "# load elmo_train_new\n",
        "pickle_in = open(\"bert_train_03032019.pickle\", \"rb\")\n",
        "bert_train_new = pickle.load(pickle_in)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6eTLVtiN67K"
      },
      "source": [
        "# load elmo_train_new\n",
        "pickle_in = open(\"bert_test_03032019.pickle\", \"rb\")\n",
        "bert_test_new = pickle.load(pickle_in)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzYDdzSIN8y8"
      },
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(bert_train_new, \n",
        "                                                  train['label'],  \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.2)\n",
        "print (ytrain.shape, yvalid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp0c-n0IN-ih"
      },
      "source": [
        "lreg = LogisticRegression()\n",
        "lreg.fit(xtrain, ytrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-6tCufUOAUy"
      },
      "source": [
        "preds_valid = lreg.predict(xvalid)\n",
        "print (f1_score(yvalid, preds_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR0HenJKOC7S"
      },
      "source": [
        "# make predictions on test set\n",
        "preds_test = lreg.predict(bert_test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JWHi7zEOE2S"
      },
      "source": [
        "# prepare submission dataframe\n",
        "sub = pd.DataFrame({'id':test['id'], 'label':preds_test})\n",
        "\n",
        "# write predictions to a CSV file\n",
        "sub.to_csv(\"sub_lreg_bert.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Iw5XznOIMt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}