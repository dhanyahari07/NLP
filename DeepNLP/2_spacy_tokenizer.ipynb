{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. spacy_tokenizer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCaSait5RFzXQWx6qUnsBC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRimWKxbmHDK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assert \"gimme\" not in [w.text for w in nlp(\"gimme!\")]\n",
        "#assert \"gimme\" not in [w.text for w in nlp('(\"...gimme...?\")')]\n",
        "\n",
        "nlp.tokenizer.add_special_case(\"...gimme...?\", [{\"ORTH\": \"...gimme...?\"}])\n",
        "#assert len(nlp(\"...gimme...?\")) == 1"
      ],
      "metadata": {
        "id": "PqE_NUhaEv3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(nlp(\"...gimme...?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DccgsKFAIQ",
        "outputId": "cd9f7483-2890-4e3e-9fab-65c574274376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[w.text for w in nlp(\"gimme!\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx3uiaziEzqN",
        "outputId": "fdcb979b-4167-41b1-a4a5-0c4a0d2c4d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gimme', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[w.text for w in nlp('(\"...gimme...?\")')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDfZR5WSE3R5",
        "outputId": "2d6192fa-5f05-4248-d0bb-2cf74b7ef469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(', '\"', '...', 'gimme', '...', '?', '\"', ')']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
        "prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
        "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "simple_url_re = re.compile(r'''^https?://''')\n"
      ],
      "metadata": {
        "id": "P8cu2fcVmuJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_tokenizer(nlp):\n",
        "  return Tokenizer(nlp.vocab, rules=special_cases,\n",
        "                                prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                url_match=simple_url_re.match)\n"
      ],
      "metadata": {
        "id": "n9Hp1bMXwkcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "0I7E1CxFww7K",
        "outputId": "1b150fcc-ab22-4423-a05c-8a5bf98cf808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a3cbc4730558>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello-world. :)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-50c5d217d0b7>\u001b[0m in \u001b[0;36mcustom_tokenizer\u001b[0;34m(nlp)\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0msuffix_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0minfix_finditer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfix_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                 url_match=simple_url_re.match)\n\u001b[0m",
            "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'url_match'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc]) \n",
        "\n",
        "special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
        "prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
        "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "#simple_url_re = re.compile(r'''^https?://''')\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, rules=special_cases,\n",
        "                                prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                #url_match=simple_url_re.match\n",
        "                     )\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxSwk9qoxDEP",
        "outputId": "c6b02144-ba69-4d90-bd65-562e797e2da6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', '-', 'world', '.', ':)']\n",
            "['hello', '-', 'world.', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "\n",
        "nlp = English()\n",
        "text = \"This is+ a- tokenizing$ sentence.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Default tokenized text\",end=' : ')\n",
        "for token in doc:\n",
        "    print(token,end=', ')\n",
        "\n",
        "suffixes = nlp.Defaults.suffixes + (r\"\\-|\\+|\\$\",)\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "print('\\nText after adding suffixes', end=' : ')\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token,end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7tMfnU0yxli",
        "outputId": "70db8876-bc62-4080-8488-95cb04166bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default tokenized text : This, is+, a-, tokenizing$, sentence, ., \n",
            "Text after adding suffixes : This, is, +, a, -, tokenizing, $, sentence, ., "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "import spacy\n",
        "\n",
        "nlp = English()\n",
        "text = \"This is a (tokenizing) sentence.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "print(\"Default tokenized text\",end=' : ')\n",
        "for token in doc:\n",
        "    print(token,end=', ')\n",
        "\n",
        "suffixes = list(nlp.Defaults.suffixes)\n",
        "suffixes.remove(\"\\(\")\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "print('\\nText after removing suffixes', end=' : ')\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token,end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSJMzLrAztkL",
        "outputId": "c14f80c6-e337-47c3-ebb6-4474b79fab34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default tokenized text : This, is, a, (, tokenizing, ), sentence, ., \n",
            "Text after removing suffixes : This, is, a, (, tokenizing, ), sentence, ., "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "class WhitespaceTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(\" \")\n",
        "        return Doc(self.vocab, words=words)\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)\n",
        "doc = nlp(\"The purpose of our lives is to be happy.\")\n",
        "print([token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2CYFmsv1Tlv",
        "outputId": "93ce1a25-3b31-4dbc-c6c7-9d083812c32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'purpose', 'of', 'our', 'lives', 'is', 'to', 'be', 'happy.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.language import Language\n",
        "import spacy\n",
        "\n",
        "text = \"this is a sentence...hello...and another sentence.\"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "print(\"Before:\", [sent.text for sent in doc.sents])\n",
        "\n",
        "@Language.(\"set_custom_boundaries\")\n",
        "def set_custom_boundaries(doc):\n",
        "    for token in doc[:-1]:\n",
        "        if token.text == \"...\":\n",
        "            doc[token.i + 1].is_sent_start = True\n",
        "    return doc\n",
        "\n",
        "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
        "doc = nlp(text)\n",
        "print(\"After:\", [sent.text for sent in doc.sents])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "GZMhQduy1pqn",
        "outputId": "3fac25c7-bccf-48a9-9ce0-8dd7fbac90ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['this is a sentence...', 'hello...and another sentence.']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c811d0409d3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"set_custom_boundaries\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_custom_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: create_pipe() missing 1 required positional argument: 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()  # just the language with no pipeline\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ELCXkhvt2xtq",
        "outputId": "a427d400-2247-43f5-e83e-a49e35488072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0a34364597a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# just the language with no pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentencizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a sentence. This is another sentence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE004\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_component_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E003] Not a valid pipeline component. Expected callable, but got 'sentencizer' (name: 'None').[E004] If you meant to add a built-in component, use `create_pipe`: `nlp.add_pipe(nlp.create_pipe('sentencizer'))`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"parser\"])\n",
        "nlp.enable_pipe(\"senter\")\n",
        "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "CXuecZ-y3Xl8",
        "outputId": "6ff10059-c4c8-4680-b850-5dde253e0450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ae66662da04d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"parser\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"senter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is a sentence. This is another sentence.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'English' object has no attribute 'enable_pipe'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "CRv1wW5c4Gs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string='\"I\\'m with you for the entire life in U.K.!\"'\n",
        "print(string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yti6g1Sf7C-q",
        "outputId": "1c3e89a2-4e67-480a-da9d-427ff83cbf57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"I'm with you for the entire life in U.K.!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(string)\n",
        "for token in doc:\n",
        "  print(token.text,end='|')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKbZ6Zri7Sp0",
        "outputId": "8de640ef-75b4-416e-ec91-6e66aaee0ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"|I|'m|with|you|for|the|entire|life|in|U.K.|!|\"|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2=nlp(u\"we're here to help! send mail to dhanya@gmail.com or visit https://dhanya.blogspot.com\")\n",
        "for t in doc2:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZ7pqvH27hHw",
        "outputId": "8a0daacc-3e42-4de7-9928-860b6a830e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we\n",
            "'re\n",
            "here\n",
            "to\n",
            "help\n",
            "!\n",
            "send\n",
            "mail\n",
            "to\n",
            "dhanya@gmail.com\n",
            "or\n",
            "visit\n",
            "https://dhanya.blogspot.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc3 =nlp(u'A 5km ola cab ride costs $10.00')\n",
        "for t in doc3:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f24iNYhQ79oA",
        "outputId": "753e6189-8c4c-44e5-9414-275e7fc9f726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "5\n",
            "km\n",
            "ola\n",
            "cab\n",
            "ride\n",
            "costs\n",
            "$\n",
            "10.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc4=nlp(u\"Let's visit St. Louis in U.S. next year.\")\n",
        "for t in doc4:\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf2ITSRp8QT_",
        "outputId": "3a5165d4-c9b7-4b7e-b275-a12ed2d9ba6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let\n",
            "'s\n",
            "visit\n",
            "St.\n",
            "Louis\n",
            "in\n",
            "U.S.\n",
            "next\n",
            "year\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DENCyAWk8gHu",
        "outputId": "8b545b21-43e1-4b17-f7ce-81fa0ad2feb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty-HA3of8mUN",
        "outputId": "9bc1c9b8-2bff-4dd5-8103-1204b6f10c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "509"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5=nlp(u'it is better to give than to receive.')\n",
        "doc5[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FezcsZIf8ob5",
        "outputId": "484438fd-6ee9-497e-a82a-222221c38f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "better"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5[2:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya9-uLU_8zef",
        "outputId": "4153e9d0-0e43-4b00-8fbb-c45f79aa942a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "better to give"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc5[-4:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LINPL4r583sS",
        "outputId": "94fdbe58-f3bf-49ae-9f2d-9c2f4f344795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "than to receive."
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc6=nlp(u'My dinner was horrible.')\n",
        "doc7=nlp(u'your dinner was delicious.')"
      ],
      "metadata": {
        "id": "umUBKVON86zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc6[3]=doc7[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "toXWh-pp9IK8",
        "outputId": "0d62afa6-1c29-41df-ae1e-a3e75a25d8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5b33895d6d44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc6\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can explain which type of token is this\n",
        "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
        "\n",
        "for token in doc8:\n",
        "    print(token.text, end=' | ')\n",
        "\n",
        "print('\\n----')\n",
        "# ents shows all entities present in all tokens\n",
        "for ent in doc8.ents:\n",
        "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWcmaLB-9M-c",
        "outputId": "6a012e04-001f-400e-8411-24cda089e511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
            "----\n",
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "Hong Kong - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc8.ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRIlXjGA-HK2",
        "outputId": "08857298-3acb-4644-b514-f8f180050390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
        "# noun_chunks finds all noun present in all tokens\n",
        "for chunk in doc9.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW4_rk7Z_IdU",
        "outputId": "ef8abe21-7690-44a1-8c25-5cf44ad67559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autonomous cars\n",
            "insurance liability\n",
            "manufacturers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
        "\n",
        "for chunk in doc10.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clXbNcSW_OU8",
        "outputId": "4baab98e-9598-421a-9713-2f06f27abc98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Red cars\n",
            "higher insurance rates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc11 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
        "\n",
        "for chunk in doc11.noun_chunks:\n",
        "    print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L51JLmlQ_VZl",
        "outputId": "434e0ce6-355f-469d-c600-eed55844b474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He\n",
            "a one-eyed, one-horned, flying, purple people-eater\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we can see how \"displacy render\" shows which type of token are these\n",
        "# and relationships between them \n",
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "yCAnpOLv_cao",
        "outputId": "2c4150bf-d1b1-400f-80aa-f70355ba4821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ffc3245a70224e329b184ccaf8f33443-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-ffc3245a70224e329b184ccaf8f33443-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-ffc3245a70224e329b184ccaf8f33443-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing types of token and there relationships in a line\n",
        "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3lcHmFfS_mRz",
        "outputId": "c26d46bb-597f-4130-ede8-ec71e566275d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the last quarter\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " sold \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly 20 thousand\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    iPods\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " for a profit of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $6 million\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'This is a sentence.')\n",
        "displacy.serve(doc, style='dep')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn3DDldL_uWX",
        "outputId": "cc19fb6e-baab-4423-e753-7999c0b9e843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dJODkoA6AB7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CWS9BjkTRoMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9hE8gDXdRoPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjnykUbFRoSM",
        "outputId": "4e6370cf-5c31-48f0-fd71-ff7863c6e03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"gimme that\")  # phrase to tokenize\n",
        "print([w.text for w in doc])  # ['gimme', 'that']\n",
        "# Add special case rule\n",
        "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
        "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
        "# Check new tokenization\n",
        "print([w.text for w in nlp(\"gimme that\")])  # ['gim', 'me', 'that']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvQ2jewlRoqX",
        "outputId": "5f79d2e8-7fd5-4853-cb5c-47615bc958ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gimme', 'that']\n",
            "['gim', 'me', 'that']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "text = '''\"Let's go!\"'''\n",
        "doc = nlp(text)\n",
        "tok_exp = nlp.tokenizer.explain(text)\n",
        "#assert [t.text for t in doc if not t.is_space] == [t[1] for t in tok_exp]\n",
        "for t in tok_exp:\n",
        "    print(t[1], \"\\t\", t[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObS4vGkQR7ce",
        "outputId": "2acfc2f2-e1b2-4110-dbc3-02cfcf1da223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\" \t PREFIX\n",
            "Let \t SPECIAL-1\n",
            "'s \t SPECIAL-2\n",
            "go \t TOKEN\n",
            "! \t SUFFIX\n",
            "\" \t SUFFIX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "doc = nlp(\"(hello)-world. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']\n",
        "\n",
        "special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
        "prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
        "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "simple_url_re = re.compile(r'''^https?://''')\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, rules=special_cases,\n",
        "                                prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                #url_match=simple_url_re.match\n",
        "                     )\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ4dvKTDSQF2",
        "outputId": "8e22636c-4f8d-41a6-ebc7-8be264151dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['(', 'hello)', '-', 'world.', ':)']\n",
            "['hello', '-', 'world.', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"hello-world $. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']\n",
        "\n",
        "suffixes = list(nlp.Defaults.suffixes + (r\"-\",))\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "doc = nlp(\"hello-world $. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTJ1hyNFSYHH",
        "outputId": "ac30868b-b8dc-4ce5-e2a3-e2c90f55c97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', '-', 'world', '$', '.', ':)']\n",
            "['hello', '-', 'world', '$', '.', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"hello-[ world ] $. :)\")\n",
        "print([t.text for t in doc])\n",
        "\n",
        "suffixes = list(nlp.Defaults.suffixes)\n",
        "suffixes.remove(\"\\\\[\")\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "doc = nlp(\"hello-[ world ] $. :)\")\n",
        "print([t.text for t in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_ttruqnS-Pr",
        "outputId": "edb135b3-175f-4d95-c54b-94066d5c842f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello-', '[', 'world', ']', '$', '.', ':)']\n",
            "['hello-[', 'world', ']', '$', '.', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I live in New York\")\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
        "print(\"After:\", [token.text for token in doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sEIjhq8Vlwg",
        "outputId": "60f6d434-d089-41d1-af2a-962f1623e737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['I', 'live', 'in', 'New', 'York']\n",
            "After: ['I', 'live', 'in', 'New York']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"I live in Berlin Kreuzberg\")\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "spans = [doc[3:5], doc[3:4], doc[4:5]]\n",
        "filtered_spans = filter_spans(spans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "KJO25D5NnY-U",
        "outputId": "2dad6f0a-d34a-4378-bc60-92cfa040d270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: ['I', 'live', 'in', 'Berlin', 'Kreuzberg']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-130ed65792f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Before:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiltered_spans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_spans' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
        "prefix_re = re.compile(r'''^[\\[\\(\"']''')\n",
        "suffix_re = re.compile(r'''[\\]\\)\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "simple_url_re = re.compile(r'''^https?://''')\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, rules=special_cases,\n",
        "                                prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,url_match=simple_url_re.match)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']"
      ],
      "metadata": {
        "id": "W8j8VAUxnmAj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "4c31ca34-018a-4715-f21d-919bca9f93e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3bd9c19ffeee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello-world. :)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ['hello', '-', 'world.', ':)']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-3bd9c19ffeee>\u001b[0m in \u001b[0;36mcustom_tokenizer\u001b[0;34m(nlp)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mprefix_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefix_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                 \u001b[0msuffix_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                 infix_finditer=infix_re.finditer,url_match=simple_url_re.match)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtokenizer.pyx\u001b[0m in \u001b[0;36mspacy.tokenizer.Tokenizer.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'url_match'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"hello-world$ :)\"\n",
        "print([t.text for t in nlp(doc)])\n",
        "\n",
        "suffixes = (\"$\",)+ nlp.Defaults.suffixes \n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "doc = \"hello-world$ :)\"\n",
        "print([t.text for t in nlp(doc)]) # ['hello', '-', 'world.', ':)']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-hh4zgH3j6r",
        "outputId": "44848fba-2d67-4854-dd03-b2a0f53d1700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', '-', 'world$', ':)']\n",
            "['hello', '-', 'world$', ':)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"I like bananabread breadbanana.\"\n",
        "#assert [t.text for t in nlp(text)] == ['I', 'like', 'bananabread', '.']\n",
        "print([t.text for t in nlp(text)])\n",
        "\n",
        "\n",
        "prefixes = (\"banana\",) + nlp.Defaults.prefixes\n",
        "suffixes = (\"banana\",) + nlp.Defaults.suffixes\n",
        "#infixes = (\"banana\",) + nlp.Defaults.infixes\n",
        "\n",
        "prefix_regex = spacy.util.compile_prefix_regex(prefixes)\n",
        "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "#infix_regex = spacy.util.compile_infix_regex(infixes)\n",
        "\n",
        "nlp.tokenizer.prefix_search = prefix_regex.search\n",
        "nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "#nlp.tokenizer.infix_finditer = infix_regex.finditer\n",
        "print([t.text for t in nlp(text)] )\n",
        "#assert [t.text for t in nlp(text)]  == ['I', 'like', 'banana', 'bread', '.']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmAxUyJf4CKO",
        "outputId": "9fd8e492-5cfa-4366-b221-101ed18b1627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'like', 'bananabread', 'breadbanana', '.']\n",
            "['I', 'like', 'banana', 'bread', 'bread', 'banana', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XqXoVA-z5HP7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}