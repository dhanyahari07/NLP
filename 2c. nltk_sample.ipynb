{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''I am a student from the University of Alabama. I\n",
    "was born in Ontario, Canada and I am a huge fan of the United\n",
    "States. I am going to get a degree in Philosophy to improve\n",
    "my chances of becoming a Philosophy professor. I have been\n",
    "working towards this goal for 4 years. I am currently enrolled\n",
    "in a PhD program. It is very difficult, but I am confident that\n",
    "it will be a good decision'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sample_word_tokens = word_tokenize(sample_text)\n",
    "sample_sent_tokens = sent_tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'student',\n",
       " 'from',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Alabama',\n",
       " '.',\n",
       " 'I',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Ontario',\n",
       " ',',\n",
       " 'Canada',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'going',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'Philosophy',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'my',\n",
       " 'chances',\n",
       " 'of',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'Philosophy',\n",
       " 'professor',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'been',\n",
       " 'working',\n",
       " 'towards',\n",
       " 'this',\n",
       " 'goal',\n",
       " 'for',\n",
       " '4',\n",
       " 'years',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'currently',\n",
       " 'enrolled',\n",
       " 'in',\n",
       " 'a',\n",
       " 'PhD',\n",
       " 'program',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'very',\n",
       " 'difficult',\n",
       " ',',\n",
       " 'but',\n",
       " 'I',\n",
       " 'am',\n",
       " 'confident',\n",
       " 'that',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'a',\n",
       " 'good',\n",
       " 'decision']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am a student from the University of Alabama.',\n",
       " 'I\\nwas born in Ontario, Canada and I am a huge fan of the United\\nStates.',\n",
       " 'I am going to get a degree in Philosophy to improve\\nmy chances of becoming a Philosophy professor.',\n",
       " 'I have been\\nworking towards this goal for 4 years.',\n",
       " 'I am currently enrolled\\nin a PhD program.',\n",
       " 'It is very difficult, but I am confident that\\nit will be a good decision']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sample_word_tokens = tokenizer.tokenize(str(sample_word_tokens))\n",
    "sample_word_tokens = [word.lower() for word in sample_word_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (1566493295.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_1906/1566493295.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    _bag_of_words = [collections.Counter(re.findall(r'\\w+',word)) for word in text]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "def bag_of_words(text):\n",
    "   _bag_of_words = [collections.Counter(re.findall(r'\\w+',word)) for word in text]\n",
    "    bag_of_words = sum(_bag_of_words, collections.Counter())\n",
    "    return bag_of_words\n",
    "sample_word_tokens_bow = bag_of_words(text=sample_word_tokens)\n",
    "print(sample_word_tokens_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97630161a1b63923bdd9a0aa586c344c3f95acdbb7ddd6c880d3dbef6642c2e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('DL': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
